{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "\n",
    "#Loading Data \n",
    "\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "#Data Cleanup \n",
    "\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary with different months as index and the keys as dataframes\n",
    "\n",
    "df['job_posted_month'] = df['job_posted_date'].dt.strftime('%b')\n",
    "months = df['job_posted_month'].unique()\n",
    "dict_months = {month: df[df['job_posted_month'] == month] for month in months}\n",
    "df_q1 = pd.concat([dict_months['Jan'], dict_months['Feb'], dict_months['Mar']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can use the toclipboard method to paste data into your clipboard \n",
    "#keyword arg sep= to indicate how i want my data to be seperated \n",
    "\n",
    "df_q1.head(3).to_clipboard(sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ",job_title_short,job_title,job_location,job_via,job_schedule_type,job_work_from_home,search_location,job_posted_date,job_no_degree_mention,job_health_insurance,job_country,salary_rate,salary_year_avg,salary_hour_avg,company_name,job_skills,job_type_skills,job_posted_month\n",
    "0,Data Analyst,Data Analyst,\"Guadalajara, Jalisco, Mexico\",via BeBee México,Full-time,False,Mexico,2023-01-14 13:18:07,False,False,Mexico,,,,Hewlett Packard Enterprise,\"['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']\",\"{'analyst_tools': ['power bi', 'tableau'], 'programming': ['r', 'python', 'sql', 'nosql']}\",Jan\n",
    "1,Data Scientist,Data Scientist,\"Zaventem, Belgium\",via BeBee Belgique,Full-time,False,Belgium,2023-01-31 13:53:38,False,False,Belgium,,,,Devoteam,\"['r', 'python', 'sql', 'pandas', 'numpy', 'scikit-learn', 'matplotlib', 'hadoop', 'spark']\",\"{'libraries': ['pandas', 'numpy', 'scikit-learn', 'matplotlib', 'hadoop', 'spark'], 'programming': ['r', 'python', 'sql']}\",Jan\n",
    "2,Data Engineer,Data Engineer,\"Fort Worth, TX\",via LinkedIn,Full-time,False,\"Texas, United States\",2023-01-25 13:24:01,False,False,United States,,,,Programmers.io,\"['sql', 'python']\",\"{'programming': ['sql', 'python']}\",Jan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can use the tocsv method to transform data into a csv format \n",
    "#you must specify the file name when you are doing this as an argument \n",
    "\n",
    "df_q1.to_csv('quarter_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "      <th>job_posted_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>San Mateo, CA</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>2023-01-28 13:07:30</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Verkada</td>\n",
       "      <td>['sql', 'python', 'aws', 'looker']</td>\n",
       "      <td>{'analyst_tools': ['looker'], 'cloud': ['aws']...</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>São Paulo, State of São Paulo, Brazil</td>\n",
       "      <td>via BeBee</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2023-01-03 23:02:27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mars</td>\n",
       "      <td>['python', 'sql', 'azure']</td>\n",
       "      <td>{'cloud': ['azure'], 'programming': ['python',...</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  job_title_short       job_title                           job_location  \\\n",
       "3   Data Engineer   Data Engineer                          San Mateo, CA   \n",
       "4  Data Scientist  Data Scientist  São Paulo, State of São Paulo, Brazil   \n",
       "\n",
       "        job_via job_schedule_type  job_work_from_home  \\\n",
       "3  via LinkedIn         Full-time               False   \n",
       "4     via BeBee         Full-time               False   \n",
       "\n",
       "             search_location      job_posted_date  job_no_degree_mention  \\\n",
       "3  California, United States  2023-01-28 13:07:30                  False   \n",
       "4                     Brazil  2023-01-03 23:02:27                  False   \n",
       "\n",
       "   job_health_insurance    job_country salary_rate  salary_year_avg  \\\n",
       "3                  True  United States         NaN              NaN   \n",
       "4                 False         Brazil         NaN              NaN   \n",
       "\n",
       "   salary_hour_avg company_name                          job_skills  \\\n",
       "3              NaN      Verkada  ['sql', 'python', 'aws', 'looker']   \n",
       "4              NaN         Mars          ['python', 'sql', 'azure']   \n",
       "\n",
       "                                     job_type_skills job_posted_month  \n",
       "3  {'analyst_tools': ['looker'], 'cloud': ['aws']...              Jan  \n",
       "4  {'cloud': ['azure'], 'programming': ['python',...              Jan  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you can read the csv to make sure it worked \n",
    "\n",
    "pd.read_csv('quarter_1.csv',index_col=0).iloc[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarly you can extractc data from pandas to an excel file \n",
    "\n",
    "df_q1.to_excel('quarter_1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use to_Sql() to_parquet() and to_pickle() simlarly \n",
    "#parquet and pickle files are efficient files for loading and managing large datasets\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
